{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "NgkGmlWaWoTq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import f1_score,confusion_matrix\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from sklearn.model_selection import KFold\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
        "from tensorflow.keras import datasets, layers, models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "bIV97EShWr7T"
      },
      "outputs": [],
      "source": [
        "# Model configuration\n",
        "batch_size = 50\n",
        "loss_function = categorical_crossentropy\n",
        "no_classes = 3\n",
        "no_epochs = 25\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "verbosity = 1\n",
        "num_folds = 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "XihHccUpWt4u",
        "outputId": "f0ded1e8-7be1-4c6d-f4a8-09a0b3fcd9e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-323a1098-2343-48eb-abe3-43e5d1e02753\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>3.6216</th>\n",
              "      <th>8.6661</th>\n",
              "      <th>-2.8073</th>\n",
              "      <th>-0.44698999999999994</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.54590</td>\n",
              "      <td>8.1674</td>\n",
              "      <td>-2.4586</td>\n",
              "      <td>-1.46210</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3.86600</td>\n",
              "      <td>-2.6383</td>\n",
              "      <td>1.9242</td>\n",
              "      <td>0.10645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.45660</td>\n",
              "      <td>9.5228</td>\n",
              "      <td>-4.0112</td>\n",
              "      <td>-3.59440</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.32924</td>\n",
              "      <td>-4.4552</td>\n",
              "      <td>4.5718</td>\n",
              "      <td>-0.98880</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.36840</td>\n",
              "      <td>9.6718</td>\n",
              "      <td>-3.9606</td>\n",
              "      <td>-3.16250</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-323a1098-2343-48eb-abe3-43e5d1e02753')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-323a1098-2343-48eb-abe3-43e5d1e02753 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-323a1098-2343-48eb-abe3-43e5d1e02753');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    3.6216  8.6661  -2.8073  -0.44698999999999994  0\n",
              "0  4.54590  8.1674  -2.4586              -1.46210  0\n",
              "1  3.86600 -2.6383   1.9242               0.10645  0\n",
              "2  3.45660  9.5228  -4.0112              -3.59440  0\n",
              "3  0.32924 -4.4552   4.5718              -0.98880  0\n",
              "4  4.36840  9.6718  -3.9606              -3.16250  0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "data=pd.read_csv(\"/content/binary_banknote.csv\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "sHtSBeQOWzMY"
      },
      "outputs": [],
      "source": [
        "#Changing pandas dataframe to numpy array\n",
        "x = data.iloc[:,:4].values\n",
        "y = data.iloc[:,4:5].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "XCFx4sEHW076"
      },
      "outputs": [],
      "source": [
        "#Standardization the data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UCfsxLwSW3Cm",
        "outputId": "acbdcf33-d0ce-43a8-d108-afccd063def4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0.],\n",
              "       [1., 0.],\n",
              "       [1., 0.],\n",
              "       ...,\n",
              "       [0., 1.],\n",
              "       [0., 1.],\n",
              "       [0., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "one_hot_encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "\n",
        "Y = one_hot_encoder.fit_transform(np.array(y).reshape(-1, 1))\n",
        "Y[:1000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "apfUXaPvW5SS"
      },
      "outputs": [],
      "source": [
        "\n",
        "oos_y = []\n",
        "oos_pred = []\n",
        "oos_yt = []\n",
        "oos_predt = []\n",
        "train_acc=[]\n",
        "test_loss=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B2F0i0p5W_SJ",
        "outputId": "6d78238d-ab11-4a4b-fbef-9a90ebfe84b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 2s 28ms/step - loss: 0.1372 - accuracy: 0.9599 - val_loss: 0.0350 - val_accuracy: 0.9818\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0252 - accuracy: 0.9918 - val_loss: 0.0164 - val_accuracy: 0.9964\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0088 - accuracy: 1.0000 - val_loss: 0.0062 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 7.7797e-04 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 6.2448e-04 - accuracy: 1.0000 - val_loss: 8.8579e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8761e-04 - accuracy: 1.0000 - val_loss: 7.0988e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.0413e-04 - accuracy: 1.0000 - val_loss: 7.2624e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.5008e-04 - accuracy: 1.0000 - val_loss: 5.1364e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 3.0193e-04 - accuracy: 1.0000 - val_loss: 4.6572e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.5232e-04 - accuracy: 1.0000 - val_loss: 4.3376e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.2523e-04 - accuracy: 1.0000 - val_loss: 4.2200e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 2.0063e-04 - accuracy: 1.0000 - val_loss: 3.5450e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.7631e-04 - accuracy: 1.0000 - val_loss: 3.4132e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.6129e-04 - accuracy: 1.0000 - val_loss: 2.6943e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.5317e-04 - accuracy: 1.0000 - val_loss: 2.6367e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.2846e-04 - accuracy: 1.0000 - val_loss: 2.6356e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.2247e-04 - accuracy: 1.0000 - val_loss: 2.3790e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 1.0992e-04 - accuracy: 1.0000 - val_loss: 2.1023e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 1.0110e-04 - accuracy: 1.0000 - val_loss: 1.8372e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 9.0125e-05 - accuracy: 1.0000 - val_loss: 1.7844e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 8.5697e-05 - accuracy: 1.0000 - val_loss: 1.6312e-04 - val_accuracy: 1.0000\n",
            "training accuracy): 1.0\n",
            " validation accuracy): {score}\n",
            "1\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 1s 25ms/step - loss: 0.2818 - accuracy: 0.8806 - val_loss: 0.0728 - val_accuracy: 0.9635\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0383 - accuracy: 0.9854 - val_loss: 0.0282 - val_accuracy: 0.9927\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0157 - accuracy: 0.9982 - val_loss: 0.0144 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0086 - accuracy: 0.9991 - val_loss: 0.0095 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 9.9053e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.3635e-04 - accuracy: 1.0000 - val_loss: 8.2964e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.4116e-04 - accuracy: 1.0000 - val_loss: 7.4316e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.1576e-04 - accuracy: 1.0000 - val_loss: 6.2874e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.3377e-04 - accuracy: 1.0000 - val_loss: 5.4287e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.6526e-04 - accuracy: 1.0000 - val_loss: 4.5854e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 4.0930e-04 - accuracy: 1.0000 - val_loss: 3.9711e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.6185e-04 - accuracy: 1.0000 - val_loss: 3.5396e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.3461e-04 - accuracy: 1.0000 - val_loss: 3.4199e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 3.0503e-04 - accuracy: 1.0000 - val_loss: 2.8770e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.5432e-04 - accuracy: 1.0000 - val_loss: 2.5953e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.3519e-04 - accuracy: 1.0000 - val_loss: 2.4190e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1349e-04 - accuracy: 1.0000 - val_loss: 2.1591e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.9388e-04 - accuracy: 1.0000 - val_loss: 1.9704e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.8101e-04 - accuracy: 1.0000 - val_loss: 1.8158e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6287e-04 - accuracy: 1.0000 - val_loss: 1.6894e-04 - val_accuracy: 1.0000\n",
            "training accuracy): 1.0\n",
            " validation accuracy): {score}\n",
            "1\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.2369 - accuracy: 0.8997 - val_loss: 0.0369 - val_accuracy: 0.9891\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.0093 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 0.0051 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0050 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 7.9100e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 7.7427e-04 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 8.7714e-04 - accuracy: 1.0000 - val_loss: 4.7253e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 7.2647e-04 - accuracy: 1.0000 - val_loss: 3.7692e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 6.3574e-04 - accuracy: 1.0000 - val_loss: 3.9398e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 5.2327e-04 - accuracy: 1.0000 - val_loss: 2.8412e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.5853e-04 - accuracy: 1.0000 - val_loss: 2.3449e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.7605e-04 - accuracy: 1.0000 - val_loss: 1.9817e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.5742e-04 - accuracy: 1.0000 - val_loss: 1.7824e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 3.1253e-04 - accuracy: 1.0000 - val_loss: 1.3622e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.6417e-04 - accuracy: 1.0000 - val_loss: 1.4689e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.2933e-04 - accuracy: 1.0000 - val_loss: 1.1714e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.0756e-04 - accuracy: 1.0000 - val_loss: 1.1410e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.0117e-04 - accuracy: 1.0000 - val_loss: 9.4670e-05 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.7507e-04 - accuracy: 1.0000 - val_loss: 8.4817e-05 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.5485e-04 - accuracy: 1.0000 - val_loss: 7.9750e-05 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 1.4903e-04 - accuracy: 1.0000 - val_loss: 6.8641e-05 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.3251e-04 - accuracy: 1.0000 - val_loss: 7.0592e-05 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 1.2224e-04 - accuracy: 1.0000 - val_loss: 6.0447e-05 - val_accuracy: 1.0000\n",
            "training accuracy): 1.0\n",
            " validation accuracy): {score}\n",
            "1\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 1s 22ms/step - loss: 0.1947 - accuracy: 0.9289 - val_loss: 0.0576 - val_accuracy: 0.9781\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0325 - accuracy: 0.9891 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 0.9982 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 0s 7ms/step - loss: 0.0069 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 0s 14ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 9.9531e-04 - accuracy: 1.0000 - val_loss: 9.9926e-04 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 7.9023e-04 - accuracy: 1.0000 - val_loss: 8.1367e-04 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.6728e-04 - accuracy: 1.0000 - val_loss: 7.2766e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.5658e-04 - accuracy: 1.0000 - val_loss: 6.4706e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 4.8461e-04 - accuracy: 1.0000 - val_loss: 5.4858e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.2992e-04 - accuracy: 1.0000 - val_loss: 5.0383e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 3.6103e-04 - accuracy: 1.0000 - val_loss: 4.4118e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2478e-04 - accuracy: 1.0000 - val_loss: 4.1789e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.9365e-04 - accuracy: 1.0000 - val_loss: 3.6018e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 2.5365e-04 - accuracy: 1.0000 - val_loss: 3.1522e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3451e-04 - accuracy: 1.0000 - val_loss: 3.3447e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.1054e-04 - accuracy: 1.0000 - val_loss: 2.7985e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.9171e-04 - accuracy: 1.0000 - val_loss: 2.6771e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7364e-04 - accuracy: 1.0000 - val_loss: 2.2795e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.6167e-04 - accuracy: 1.0000 - val_loss: 2.3332e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.4608e-04 - accuracy: 1.0000 - val_loss: 2.2056e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.3618e-04 - accuracy: 1.0000 - val_loss: 2.1612e-04 - val_accuracy: 1.0000\n",
            "training accuracy): 1.0\n",
            " validation accuracy): {score}\n",
            "1\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/25\n",
            "22/22 [==============================] - 1s 23ms/step - loss: 0.2904 - accuracy: 0.8441 - val_loss: 0.0649 - val_accuracy: 0.9708\n",
            "Epoch 2/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 0.0389 - accuracy: 0.9854 - val_loss: 0.0165 - val_accuracy: 0.9964\n",
            "Epoch 3/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0122 - accuracy: 0.9982 - val_loss: 0.0086 - val_accuracy: 1.0000\n",
            "Epoch 4/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0068 - accuracy: 1.0000 - val_loss: 0.0058 - val_accuracy: 1.0000\n",
            "Epoch 5/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0047 - accuracy: 1.0000 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 6/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 7/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 8/25\n",
            "22/22 [==============================] - 0s 11ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 9/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 10/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 11/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 8.2214e-04 - accuracy: 1.0000 - val_loss: 7.5821e-04 - val_accuracy: 1.0000\n",
            "Epoch 12/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 7.0519e-04 - accuracy: 1.0000 - val_loss: 6.8639e-04 - val_accuracy: 1.0000\n",
            "Epoch 13/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 6.0290e-04 - accuracy: 1.0000 - val_loss: 5.7331e-04 - val_accuracy: 1.0000\n",
            "Epoch 14/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 5.1200e-04 - accuracy: 1.0000 - val_loss: 4.9707e-04 - val_accuracy: 1.0000\n",
            "Epoch 15/25\n",
            "22/22 [==============================] - 0s 12ms/step - loss: 4.7027e-04 - accuracy: 1.0000 - val_loss: 4.5936e-04 - val_accuracy: 1.0000\n",
            "Epoch 16/25\n",
            "22/22 [==============================] - 0s 13ms/step - loss: 4.1266e-04 - accuracy: 1.0000 - val_loss: 4.0808e-04 - val_accuracy: 1.0000\n",
            "Epoch 17/25\n",
            "22/22 [==============================] - 0s 8ms/step - loss: 4.2924e-04 - accuracy: 1.0000 - val_loss: 3.6146e-04 - val_accuracy: 1.0000\n",
            "Epoch 18/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 3.2286e-04 - accuracy: 1.0000 - val_loss: 3.1986e-04 - val_accuracy: 1.0000\n",
            "Epoch 19/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.8470e-04 - accuracy: 1.0000 - val_loss: 2.6774e-04 - val_accuracy: 1.0000\n",
            "Epoch 20/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.5354e-04 - accuracy: 1.0000 - val_loss: 2.5239e-04 - val_accuracy: 1.0000\n",
            "Epoch 21/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 2.3118e-04 - accuracy: 1.0000 - val_loss: 2.2610e-04 - val_accuracy: 1.0000\n",
            "Epoch 22/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 2.0964e-04 - accuracy: 1.0000 - val_loss: 2.1416e-04 - val_accuracy: 1.0000\n",
            "Epoch 23/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.9539e-04 - accuracy: 1.0000 - val_loss: 1.8814e-04 - val_accuracy: 1.0000\n",
            "Epoch 24/25\n",
            "22/22 [==============================] - 0s 9ms/step - loss: 1.7571e-04 - accuracy: 1.0000 - val_loss: 1.7522e-04 - val_accuracy: 1.0000\n",
            "Epoch 25/25\n",
            "22/22 [==============================] - 0s 10ms/step - loss: 1.5983e-04 - accuracy: 1.0000 - val_loss: 1.6332e-04 - val_accuracy: 1.0000\n",
            "training accuracy): 1.0\n",
            " validation accuracy): {score}\n",
            "1\n",
            "\n",
            "\n",
            " average training accuracy: 1.0\n",
            "average validation loss:0.0001543892933113966\n",
            "classwise   training accuracy :\n",
            "[1. 1.]\n",
            "\n",
            "\n",
            "classwise   validation accuracy :\n",
            "[1. 1.]\n",
            "validation accuracy: 1.0\n",
            "f1 score is :\n",
            "1.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       761\n",
            "           1       1.00      1.00      1.00       610\n",
            "\n",
            "    accuracy                           1.00      1371\n",
            "   macro avg       1.00      1.00      1.00      1371\n",
            "weighted avg       1.00      1.00      1.00      1371\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Dependencies\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 0\n",
        "for train, test in kfold.split(X, Y):\n",
        "  fold_no = fold_no + 1\n",
        "  model = Sequential()\n",
        "  model.add(Dense(30, input_dim=4, activation='tanh'))\n",
        "  model.add(Dense(20, activation='relu'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  opt=tf.keras.optimizers.Adam(learning_rate=.01)\n",
        "  \n",
        "  # Compile the model\n",
        "  model.compile(loss=loss_function,\n",
        "                optimizer=opt,\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  #Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "  count=0\n",
        "  epcount=0\n",
        "  # Fit data to model\n",
        "  history = model.fit(X[train], Y[train],\n",
        "              batch_size=batch_size,\n",
        "              epochs=no_epochs,\n",
        "              validation_data=(X[test], Y[test]),\n",
        "              verbose=verbosity)\n",
        "\n",
        "  test_loss.append((history.history['val_loss'][-1]))\n",
        "  #predicting accuracy of trained model\n",
        "  predict_xt=model.predict(X[train])\n",
        "  y_predt=np.argmax(predict_xt,axis=-1)\n",
        "  oos_yt.append(Y[train])\n",
        "  oos_predt.append(y_predt)    \n",
        "  y_train=np.argmax(Y[train], axis=-1) \n",
        "  score = metrics.accuracy_score(y_train, y_predt)\n",
        "  print(f\"training accuracy): {score}\")\n",
        "  \n",
        "  predict_x=model.predict(X[test])\n",
        "  y_pred=np.argmax(predict_x,axis=-1)\n",
        "  oos_y.append(Y[test])\n",
        "  oos_pred.append(y_pred)    \n",
        "  y_test=np.argmax(Y[test], axis=-1) \n",
        "  score = metrics.accuracy_score(y_test, y_pred)\n",
        "  print(\" validation accuracy): {score}\")\n",
        "  for i in history.history['val_accuracy']:\n",
        "    count=count+1\n",
        "    if i>=0.7905:\n",
        "      epcount=count\n",
        "      break\n",
        "  print(epcount)\n",
        "print(\"\\n\")\n",
        "test_loss=(np.sum(test_loss)/5)\n",
        "oos_yt = np.concatenate(oos_yt)\n",
        "oos_predt = np.concatenate(oos_predt)\n",
        "oos_y_comparet = np.argmax(oos_yt,axis=1) # For accuracy calculation\n",
        "score1 = metrics.accuracy_score(oos_y_comparet, oos_predt)\n",
        "print(f\" average training accuracy: {score1}\") \n",
        "cm1 = confusion_matrix(oos_y_comparet, oos_predt)\n",
        "print(f\"average validation loss:{test_loss}\")\n",
        "print(\"classwise   training accuracy :\")\n",
        "print(cm1.diagonal()/cm1.sum(axis=1))\n",
        "oos_y = np.concatenate(oos_y)\n",
        "oos_pred = np.concatenate(oos_pred)\n",
        "oos_y_compare = np.argmax(oos_y,axis=1) # For accuracy calculation\n",
        "print(\"\\n\")\n",
        "score = metrics.accuracy_score(oos_y_compare, oos_pred)\n",
        "cm = confusion_matrix(oos_y_compare, oos_pred)\n",
        "print(\"classwise   validation accuracy :\")\n",
        "print(cm.diagonal()/cm.sum(axis=1))\n",
        "print(f\"validation accuracy: {score}\")     \n",
        "print(\"f1 score is :\")\n",
        "print(f1_score(oos_y_compare.tolist(), oos_pred.tolist(), average='macro'))\n",
        "\n",
        "print(metrics.classification_report(oos_y_compare,oos_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "WFKVzjmkXHNG",
        "outputId": "8a3e5c1e-93e8-43a6-bfa3-e5e580535d4b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Validation accuracy vs loss')\n",
        "plt.ylabel('y-axis')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Accuracy', 'Loss'], loc='center right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "K fold with epochs modifications.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}